# Recording 3: Targets & Sustainability

**Duration:** ~10 minutes
**Slides:** 1-7
**Core message:** Measuring implementation success requires careful thinking: meaningful targets, awareness of Goodhart's Law, and honest attention to whether change sustains. The widespread "70% of changes fail" claim has no empirical basis—and believing it can become a self-fulfilling prophecy for consultants, client leaders, and change champions alike.

---

## Slide 1: Title

**Visual:** Title slide

> "Targets & Sustainability"

**Story to tell:**
We've talked about building partnerships and planning with humility. But at some point, someone will ask the obvious question: "Did it work?"

That turns out to be a surprisingly difficult question to answer well. In this recording, we'll look at how to set meaningful targets, why change often doesn't stick, and then confront a widely cited statistic that may be doing more harm than good.

---

## Slide 2: Goodhart's Law

**Visual:** "When a measure becomes a target, it ceases to be a good measure" — with examples

**Story to tell:**
If we're going to measure implementation success, we need targets. But targets are dangerous.

Goodhart's Law: "When a measure becomes a target, it ceases to be a good measure."

This sounds abstract, so let me give you examples.

Hospital waiting time targets: patients held in ambulances outside A&E so they hadn't officially "arrived" and weren't yet "waiting."

Call centre duration targets: calls ended prematurely—problem "resolved" as far as the metric was concerned, but not for the customer.

Educational attainment targets: teaching to the test. Students pass exams but don't develop understanding.

In each case, the measure was sensible. The problem arose when it became a target—because people optimised for the target rather than the underlying goal the target was meant to represent.

---

## Slide 3: Designing Better Targets

**Visual:** Five principles for better targets

**Story to tell:**
This doesn't mean we shouldn't set targets. It means we need to design them carefully.

**Multiple measures**: Balance different aspects of performance so optimising one doesn't destroy another.

**Leading and lagging indicators**: Track activities and inputs, not just outcomes. By the time a lagging indicator moves, it may be too late to intervene.

**Qualitative alongside quantitative**: Numbers tell you what happened. Narrative tells you why.

**Beware perverse incentives**: For every target, ask "how could this be gamed?" If you can think of a way, someone will find it.

**Review and adapt**: Targets should evolve as understanding develops. A target that made sense at the start may be meaningless six months in.

SMART targets—Specific, Measurable, Achievable, Relevant, Time-bound—are a useful starting point. But a target can be perfectly SMART and still be harmful if it creates perverse incentives.

---

## Slide 4: Sustaining Change

**Visual:** Threats to sustainability on one side, strategies on the other

**Story to tell:**
The ultimate test of implementation isn't whether the change happens. It's whether the change *persists* after consultants leave.

And here's the uncomfortable reality: many changes don't persist. Key champions leave. Competing priorities emerge. Initial enthusiasm fades. Systems revert to familiar patterns. New leadership has different priorities.

The strategies for sustainability connect back to everything we've discussed:

**Embed in systems**—integrate the change into processes, policies, and technology so it doesn't depend on individual commitment.

**Develop capability**—this is the Recording 1 argument again. If only the consultant understood the new approach, it dies when they leave.

**Align incentives**—make sure reward systems support the new behaviours, not the old ones.

**Plan handover explicitly**—don't let the end of the engagement be an afterthought.

The transition is complete when internal teams can solve problems independently, systems support the new ways of working, and—here's the real test—the consultant's absence wouldn't reverse progress.

---

## Slide 5: The 70% Myth

**Visual:** The Beer & Nohria quote, then crossed out / marked "no evidence"

**Story to tell:**
Now. You might be thinking: "All this careful measurement is beside the point—everyone knows that about 70% of all change initiatives fail." It's everywhere—textbooks, consulting pitches, conference presentations. It's become one of those facts that everyone knows.

Except it isn't a fact. It's a myth.

The claim traces back to Beer and Nohria's 2000 HBR article "Cracking the Code of Change." But they provided no evidence. No study. No data. No definition of what "fail" means. It was simply asserted.

Mark Hughes systematically traced this statistic through the literature. What he found was academic matryoshka dolls—each source citing another source, citing another source, all the way back to unsupported original claims. Some traces lead to Hammer and Champy's 1993 admission that their estimate of BPR failure rates was, in their own words, "unscientific."

A claim repeated often enough becomes conventional wisdom—even without evidence.

---

## Slide 6: Why the Myth Persists—and Why It's Dangerous

**Visual:** Functions the myth serves on one side; the nocebo effect on the other

**Story to tell:**
Hughes asks a better question than "is it true?"—he asks "what purpose does it serve?" And the answer is revealing.

**Legitimation**: It justifies consultant involvement. If change is so hard that 70% fail, you'd better hire experts.

**Expectation setting**: It prepares clients for difficulty. If most changes fail, moderate success looks impressive.

**Risk management**: It protects consultants when things go wrong. "Well, 70% fail—we were always up against the odds."

**Selling**: It creates demand for change management expertise. Fear sells.

Notice who benefits from this narrative. Predominantly: consulting firms. Which is who most frequently cite it.

But here's what should really concern you. In medicine, there's the *nocebo effect*—the opposite of a placebo. When patients are told a treatment probably won't work, outcomes genuinely worsen. Expectations shape reality.

The same logic applies here. Think about the consultant who walks into an engagement having internalised "most of these fail." They hedge. They protect themselves. They invest less fully because, on some level, failure feels like the default.

Now think about the client-side leader who's been told the same thing. Why would you champion a change if the odds are stacked against you? Why put your reputation on the line for something that "probably won't work"? And think about the middle managers and team leads you need as change champions. If the prevailing narrative is that change usually fails, the rational response is to keep your head down and wait it out.

The 70% myth doesn't just describe failure—it *produces* it. It gives everyone involved permission to disengage. A more honest framing: success and failure depend on what you're trying to change, how you define success, and the organisational context. Most changes produce mixed results. "Did it work?" is rarely a yes/no question—which is exactly why we need the careful measurement we discussed earlier.

---

## Slide 7: Summary

**Visual:** Three key takeaways for the week

**Story to tell:**
Let me close the week's recordings by pulling the threads together across all three.

Implementation is where consulting value is realised or lost. It requires three things:

**Partnership over dependency**: Build client capability. Shift towards the Navigator role. Plan with the end in mind.

**Adaptive planning**: Diagnose tame vs wicked. Plan with humility. Hold the plan loosely while staying clear on direction.

**Honest measurement**: Set targets carefully, watch for Goodhart's Law, and plan for sustainability from day one. And reject narratives that normalise failure—because believing change will fail is one of the surest ways to make it so.

The written content goes deeper on business cases, change approaches from Week 3 applied to implementation, and detailed sustainability strategies. The readings—Block and Edmonstone—give you two complementary perspectives: the practitioner and the critical thinker.

See you at the live session.

---

## Sources

- Beer, M. & Nohria, N. (2000). Cracking the code of change. *Harvard Business Review*
- Hughes, M. (2011). Do 70 per cent of all organizational change initiatives really fail? *Journal of Change Management*
- Goodhart, C. (1975). Goodhart's Law (via Strathern, 1997)
- Block, P. (2011). *Flawless Consulting* (3rd ed.)
