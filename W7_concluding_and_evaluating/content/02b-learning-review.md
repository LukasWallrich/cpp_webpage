## 3. Learning and review

This section expands on the learning dimension introduced in Part 2's video. While the video focuses on handover and closure practices, here we explore *how* to structure learning at the end of an engagement, for the consultant, the team, and the client organisation.

### Structured end-of-engagement reviews

End-of-engagement reviews go by many names: retrospectives, after-action reviews, lessons learned sessions, post-project reviews. Whatever the label, the purpose is the same: creating a structured opportunity to reflect on what happened, why, and what to do differently next time.

The most effective reviews share several characteristics:

**Separation from evaluation**: Reviews focused on learning need to be kept distinct from reviews focused on proving success (recall Easterby-Smith's [-@easterbysmith1994] distinction from Part 1). If people fear that honest reflection will be used against them, they won't be honest.

**Inclusion of multiple perspectives**: Just as evaluation findings depend on who you ask, learning is richest when it draws on different experiences of the same engagement. Client staff, project team members, and stakeholders often have very different insights about what worked and why.

**Timeliness**: Reviews conducted months after an engagement ends suffer from hindsight bias and faded memories. The best time to capture learning is soon after key milestones or at project end, while experiences are still fresh.

:::framework
**Key questions for end-of-engagement reviews**:

1. **What did we set out to achieve?** (Revisit the original objectives and success criteria)
2. **What actually happened?** (Factual account before interpretation)
3. **Why did it happen that way?** (Root causes, not blame)
4. **What will we do differently next time?** (Specific, actionable commitments)
5. **What should we keep doing?** (Reinforcing what worked)
:::

### Single-loop and double-loop learning

Argyris [-@argyris1991] argues that many professionals, including consultants, are surprisingly poor at learning from experience, precisely because they are so accustomed to succeeding. When things go wrong, they tend to look for external explanations rather than examining their own assumptions and behaviours.

Argyris distinguishes between two types of learning:

| | Single-loop learning | Double-loop learning |
|--|---|---|
| **Focus** | Did we do things right? | Did we do the right things? |
| **Response to problems** | Adjust techniques and methods | Question underlying assumptions |
| **Example** | "Next time we'll allow more time for stakeholder engagement" | "Why did we assume stakeholders would support this without early involvement?" |

Most post-project reviews default to single-loop learning: identifying tactical improvements while leaving deeper assumptions unexamined. Double-loop learning requires questioning *why* the project was structured as it was, *why* certain stakeholders were prioritised, and *whether the problem was correctly defined* in the first place.

This is difficult because it requires vulnerability: acknowledging that your professional judgement may have been flawed, not just your execution.

### Reflective practice for consultants

Sch√∂n [-@schon1983] introduced the distinction between **reflection-in-action** (thinking on your feet during practice) and **reflection-on-action** (looking back systematically afterwards). Both are essential for building consulting expertise, but reflection-on-action is particularly relevant at engagement end.

**Reflection-in-action** is what experienced consultants do intuitively: noticing when a workshop isn't landing and adjusting in real time, sensing client resistance and shifting approach. This develops through experience but can be accelerated through deliberate attention.

**Reflection-on-action** is the structured process of looking back on practice to understand what happened and why. At the end of an engagement, this means asking:

- What surprised me during this engagement?
- Where did my initial assumptions prove wrong?
- What skills or knowledge gaps did I discover?
- How did my relationship with the client evolve, and why?
- What would I do differently with the benefit of hindsight?

Individual reflection complements team reviews. Team reviews capture collective learning; individual reflection captures personal professional development, the kind of tacit knowledge that is hardest to codify (connecting to Part 4's discussion of knowledge types).

We will return to reflective practice experientially in Week 9, where you will have the opportunity to apply these ideas to your own consulting development.

### Helping clients learn from the engagement

Beyond transferring the deliverables (covered in Part 2's handover discussion), consultants can help clients develop their capacity to learn from the experience itself:

**Building internal review capability**: Rather than just conducting a final review *for* the client, consider teaching them *how* to conduct reviews themselves. This builds lasting capability and connects to Block's [-@block2011] principle of working yourself out of a job.

**Surfacing patterns**: Clients may not see patterns across their own history with change. A consultant can help by asking: "Is this the first time you've faced this kind of challenge? What happened last time? What's different now?"

**Naming what was learned about process**: Beyond the content of the engagement (the strategy, the restructuring, the new system), clients can learn about *how they manage change*. Did internal communication work? Were the right people involved in decisions? How did the organisation handle resistance?

:::reflect
Think about a significant learning experience in your professional life. Was the learning primarily from a structured review, from individual reflection, or from something else entirely? What conditions made that learning possible?
:::
